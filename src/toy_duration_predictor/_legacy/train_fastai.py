# --- 0. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---
# ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë¨¼ì € í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
# pip install torch fastai wandb gradio

import torch
import torch.nn as nn
from torch.utils.data import TensorDataset
from fastai.data.core import DataLoaders
from fastai.learner import Learner, pÃ©rdida_Calculada
from fastai.callback.wandb import WandbCallback
from fastai.callback.schedule import lr_find
import numpy as np
import pandas as pd
import gradio as gr
import os

# --- 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ìƒìˆ˜ ì •ì˜ ---
MAX_SEQ_LENGTH = 32
NUM_SINGERS = 100
NUM_SAMPLES = 100000
BATCH_SIZE = 256

# ëª¨ë¸ êµ¬ì¡° ê´€ë ¨ íŒŒë¼ë¯¸í„° (fastai Learnerì— ì „ë‹¬)
SID_EMBEDDING_DIM = 16
GRU_UNITS = 128
NUM_GRU_LAYERS = 2

# --- 2. PyTorch ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ (fastaiëŠ” ìˆœìˆ˜ PyTorch ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©) ---
class DurationPredictorGRU(nn.Module):
    """
    fastaiì˜ Learnerê°€ ë˜í•‘í•  ìˆœìˆ˜ PyTorch ëª¨ë¸.
    """
    def __init__(self, num_singers, sid_embedding_dim, gru_units, num_gru_layers):
        super().__init__()
        self.sid_embedding = nn.Embedding(num_singers, sid_embedding_dim)
        gru_input_dim = 1 + sid_embedding_dim
        self.gru = nn.GRU(
            gru_input_dim, gru_units, num_gru_layers,
            batch_first=True, bidirectional=True
        )
        self.fc_out = nn.Linear(gru_units * 2, 1)

    def forward(self, x):
        # fastaiëŠ” ì…ë ¥ì„ íŠœí”Œë¡œ ë¬¶ì–´ì„œ ì „ë‹¬í•©ë‹ˆë‹¤.
        duration_input, sid_input = x
        sid_embedded = self.sid_embedding(sid_input)
        duration_reshaped = duration_input.unsqueeze(-1)
        
        features = torch.cat([duration_reshaped, sid_embedded], dim=-1)
        gru_output, _ = self.gru(features)
        predictions = self.fc_out(gru_output)
        return predictions

# --- 3. ë°ì´í„° ì¤€ë¹„ ---
print("--- ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘... ---")

# ê°€ìƒì˜ ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± (DataFrameìœ¼ë¡œ ê´€ë¦¬í•˜ë©´ í¸ë¦¬)
data = {
    'durations': [torch.rand(MAX_SEQ_LENGTH) for _ in range(NUM_SAMPLES)],
    'sids': [torch.randint(0, NUM_SINGERS, (MAX_SEQ_LENGTH,)) for _ in range(NUM_SAMPLES)],
    'labels': [d * torch.rand_like(d) * 2 for d in [d['durations'] for d in [{'durations': data} for data in [{'durations': torch.rand(MAX_SEQ_LENGTH)}] * NUM_SAMPLES]]]
}
df = pd.DataFrame(data)

# í›ˆë ¨(80%), ê²€ì¦(10%), í…ŒìŠ¤íŠ¸(10%) ì¸ë±ìŠ¤ ìƒì„±
np.random.seed(42)
indices = np.random.permutation(len(df))
test_split_idx = int(len(df) * 0.1)
val_split_idx = int(len(df) * 0.2)

test_indices = indices[:test_split_idx]
val_indices = indices[test_split_idx:val_split_idx]
train_indices = indices[val_split_idx:]

# fastaiì˜ DataLoaders ê°ì²´ ìƒì„±
# ì…ë ¥(x)ì€ íŠœí”Œ, ì¶œë ¥(y)ì€ ë‹¨ì¼ í…ì„œë¡œ êµ¬ì„±
train_ds = TensorDataset(torch.stack(df.loc[train_indices, 'durations'].tolist()),
                         torch.stack(df.loc[train_indices, 'sids'].tolist()),
                         torch.stack(df.loc[train_indices, 'labels'].tolist()).unsqueeze(-1))

val_ds = TensorDataset(torch.stack(df.loc[val_indices, 'durations'].tolist()),
                       torch.stack(df.loc[val_indices, 'sids'].tolist()),
                       torch.stack(df.loc[val_indices, 'labels'].tolist()).unsqueeze(-1))

test_ds = TensorDataset(torch.stack(df.loc[test_indices, 'durations'].tolist()),
                        torch.stack(df.loc[test_indices, 'sids'].tolist()),
                        torch.stack(df.loc[test_indices, 'labels'].tolist()).unsqueeze(-1))

# fastaiì˜ DataLoadersë¡œ ë˜í•‘
# ì…ë ¥(x)ì„ íŠœí”Œë¡œ ë¬¶ê¸° ìœ„í•´ x_cat=2
dls = DataLoaders.from_dsets(train_ds, val_ds, bs=BATCH_SIZE, device='cuda' if torch.cuda.is_available() else 'cpu')
test_dl = dls.test_dl(test_ds, with_labels=True)

print(f"í›ˆë ¨ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(train_ds)}")
print(f"ê²€ì¦ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(val_ds)}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(test_ds)}")

# --- 4. fastai Learner ìƒì„± ë° í›ˆë ¨ ---

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤í™”
model = DurationPredictorGRU(NUM_SINGERS, SID_EMBEDDING_DIM, GRU_UNITS, NUM_GRU_LAYERS)

# Learner ìƒì„± (ëª¨ë¸, ë°ì´í„°, ì†ì‹¤ í•¨ìˆ˜, ì½œë°± ë“±ì„ ëª¨ë‘ ë¬¶ìŒ)
learn = Learner(dls, model, loss_func=nn.MSELoss(), cbs=WandbCallback(log_preds=False))

# --- 4a. ìµœì ì˜ í•™ìŠµë¥  íƒìƒ‰ (Optuna ëŒ€ì‹  ì‚¬ìš©) ---
print("\n--- 1. ìµœì ì˜ í•™ìŠµë¥  íƒìƒ‰ ì‹œì‘ (fastai lr_find) ---")
# lr_find() ì‹¤í–‰ í›„, ê°€ì¥ ê°€íŒŒë¥¸ ê¸°ìš¸ê¸°ë¥¼ ê°€ì§„ ì§€ì ì˜ í•™ìŠµë¥ ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì 
suggested_lr = learn.lr_find(suggest_funcs=(lr_find.valley, lr_find.slide))
print(f"fastaiê°€ ì œì•ˆí•˜ëŠ” ìµœì  í•™ìŠµë¥ : {suggested_lr.valley:.2e}")

# --- 4b. ëª¨ë¸ í›ˆë ¨ ---
print("\n--- 2. ì œì•ˆëœ í•™ìŠµë¥ ë¡œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ---")
# fine_tuneì€ í—¤ë“œëŠ” ì œì•ˆëœ í•™ìŠµë¥ ë¡œ, ëª¸í†µì€ ë” ë‚®ì€ í•™ìŠµë¥ ë¡œ í›ˆë ¨í•˜ëŠ” ë“±
# ì—¬ëŸ¬ best practiceê°€ ì ìš©ëœ ê°•ë ¥í•œ í›ˆë ¨ ë©”ì†Œë“œ
learn.fine_tune(10, base_lr=suggested_lr.valley)

print("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")

# --- 5. ìµœì¢… ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ì…‹) ---
print("\n--- 3. ìµœì¢… ëª¨ë¸ í‰ê°€ ì‹œì‘ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì‚¬ìš©) ---")
# get_predsë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ì…‹ì— ëŒ€í•œ ì˜ˆì¸¡ ë° ì†ì‹¤ ê³„ì‚°
preds, targs, test_loss = learn.get_preds(dl=test_dl, with_loss=True)
print(f"ìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤ (MSE): {test_loss.item():.6f}")

# --- 6. Gradio ë°ëª¨ ì‹¤í–‰ ---
print("\n--- 4. Gradio ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ ---")
learn.model.eval() # ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜

def predict_duration_fastai(singer_id_str, duration_sequence_str):
    try:
        # ì…ë ¥ íŒŒì‹± ë° í…ì„œí™”
        singer_id = int(singer_id_str)
        durations = [float(d.strip()) for d in duration_sequence_str.split(',')]
        
        if len(durations) > MAX_SEQ_LENGTH:
            durations = durations[:MAX_SEQ_LENGTH]
        else:
            durations += [0] * (MAX_SEQ_LENGTH - len(durations))

        duration_tensor = torch.tensor(durations, dtype=torch.float32).unsqueeze(0)
        sid_tensor = torch.full_like(duration_tensor, singer_id, dtype=torch.long)

        # fastai Learnerë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡
        # learn.predictëŠ” ë‹¨ì¼ ì•„ì´í…œì— ëŒ€í•œ ì˜ˆì¸¡ê³¼ ë””ì½”ë”©ì„ ìˆ˜í–‰
        # ì—¬ê¸°ì„œëŠ” ëª¨ë¸ ì§ì ‘ í˜¸ì¶œì´ ë” ê°„ë‹¨
        with torch.no_grad():
            prediction = learn.model((duration_tensor.to(learn.dls.device), sid_tensor.to(learn.dls.device)))
        
        output_sequence = prediction.squeeze().cpu().tolist()
        return ", ".join([f"{x:.4f}" for x in output_sequence])

    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
iface = gr.Interface(
    fn=predict_duration_fastai,
    inputs=[
        gr.Textbox(label="ê°€ìˆ˜ ID (Singer ID)", value="10"),
        gr.Textbox(label="ìŒí‘œ ê¸¸ì´ ì‹œí€€ìŠ¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
                   value="0.1, 0.2, 0.15, 0.5, 0.4, 0.12, 0.1, 0.25")
    ],
    outputs=gr.Textbox(label="ì˜ˆì¸¡ëœ ìŒí‘œ ê¸¸ì´ ì‹œí€€ìŠ¤"),
    title="ğŸµ Duration Predictor (fastai + MLOps)",
    description="fastaië¡œ í›ˆë ¨ëœ ëª¨ë¸ì…ë‹ˆë‹¤. ê°€ìˆ˜ IDì™€ ì •ê·œ ìŒí‘œ ê¸¸ì´ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥í•˜ë©´, í•´ë‹¹ ê°€ìˆ˜ì˜ ê³ ìœ í•œ ë¦¬ë“¬ í‘œí˜„ì´ ì ìš©ëœ ìŒí‘œ ê¸¸ì´ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤."
)
iface.launch()

